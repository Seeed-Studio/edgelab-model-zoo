{
    "uuid": "caa42993be588cdb959cfc00c71d8076",
    "name": "person Detection",
    "version": "1.0.0",
    "category": "Object Detection",
    "algorithm": "Swift-YOLO",
    "description": "The model is a Swift-YOLO model trained on the person detection dataset.",
    "dataset": {
        "name": "",
        "url": "https://universe.roboflow.com/hanzhou-7mktt/ssperson/dataset/7",
        "download": "https://universe.roboflow.com/ds/RFhocq9L2g?key=Ttmf6Fgq19"
    },
    "network": {
        "batch": 1,
        "input": {
            "type": "image",
            "shape": [
                192,
                192,
                3
            ],
            "remark": "The input image should be resized to 192x192 pixels."
        },
        "output": {
            "type": "bbox",
            "shape": [
                2268,
                6
            ],
            "remark": "The output is a 2268x6 tensor, where 2268 is the number of candidate boxes and 6 is [x, y, w, h, score, [class]]"
        }
    },
    "config": {
        "url": "configs/swift_yolo/swift_yolo_shuff_1xb16_300e_coco.py"
    },
    "guidelines": "",
    "license": "MIT",
    "image": "https://files.seeedstudio.com/sscma/static/detection_coco.png",
    "classes": [
        "person"
    ],
    "benchmark": [
        {
            "backend": "PyTorch",
            "precision": "FLOAT32",
            "metrics": {
                "mAP(%)": 95.4,
                "Flops(M)": 194,
                "Params(M)": 0.7
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/detection/person/swift_yolo_shuffle_coco_320_float32_sha1_a5927bd6a6c6569d27edb98da946a8e75a8d816f.pth",
            "author": "Seeed Studio",
            "checksum": "md5:79a08ceed5d9ff8e033c8a6ffd5c6093"
        },
        {
            "backend": "ONNX",
            "precision": "FLOAT32",
            "metrics": {
                "mAP(%)": 95.4,
                "Params(M)": 0.7
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/detection/person/swift_yolo_shuffle_coco_320_float32_sha1_20bc2c8517a8e42699bf46f1409f7541e52345ac.onnx",
            "author": "Seeed Studio",
            "checksum": "md5:2ca5762b62cc8ff143d44c3233a3b2c5"
        },
        {
            "backend": "TFLite",
            "precision": "FLOAT32",
            "metrics": {
                "mAP(%)": 95.4,
                "Peek RAM(MB)": 1.2
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/detection/person/swift_yolo_shuffle_coco_320_float32_sha1_5dfa1a16d27ef347c0173c5297395963760fcc57.tflite",
            "author": "Seeed Studio",
            "checksum": "md5:42c97149bcf0a241951a0756f1cc2a31"
        },
        {
            "backend": "TFLite",
            "precision": "INT8",
            "device": [
                "xiao_esp32s3"
            ],
            "metrics": {
                "mAP(%)": 91.7,
                "Peek RAM(MB)": 0.35,
                "Inference(ms)": {
                    "xiao_esp32s3": 200.0
                }
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/detection/person/swift_yolo_shuffle_coco_320_int8_sha1_3b0a6d7fd95e9dd21902beae6fa2d1cd0807bd7b.tflite",
            "author": "Seeed Studio",
            "checksum": "md5:e2f7586cd6389f3e54acb01912681dd6"
        },
        {
            "backend": "TFLite(vela)",
            "precision": "INT8",
            "device": [
                "grove_vision_ai_we2"
            ],
            "metrics": {
                "mAP(%)": 91.7,
                "Peek RAM(MB)": 0.35,
                "Inference(ms)": {
                    "grove_vision_ai_we2": 46.0
                }
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/detection/person/swift_yolo_shuffle_coco_320_int8_sha1_3b0a6d7fd95e9dd21902beae6fa2d1cd0807bd7b_vela.tflite",
            "author": "Seeed Studio",
            "checksum": "md5:053f314c9f8c31147aab8c96412c0773"
        }
    ],
    "benchmark_note": {
        "Evaluation Parameters": " Confidence Threshold: 0.001, IoU Threshold: 0.55, mAP Eval IoU: 0.50."
    }
}