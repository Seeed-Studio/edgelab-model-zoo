{
    "uuid": "56c3c48269f96e628fc6e1bdcebf176a",
    "name": "Person Classification",
    "version": "1.0.0",
    "category": "Image Classification",
    "algorithm": "MobileNetV2 0.35 Rep",
    "description": "The model is a vision model designed for CIFAR-10 classification. It utilizes the [SSCMA](https://github.com/Seeed-Studio/SSCMA) training and employs the MobileNetV2 (0.35) Rep algorithm.",
    "dataset": {
        "name": "VWW",
        "url": "https://github.com/Mxbonn/visualwakewords",
        "download": "https://universe.roboflow.com/ds/rvZt8qZfBp?key=WDJI0KBhlY"
    },
    "network": {
        "batch": 1,
        "input": {
            "type": "image",
            "shape": [
                96,
                96,
                3
            ],
            "remark": "The input image should be resized to 96x96 pixels"
        },
        "output": {
            "type": "classification",
            "shape": [
                2
            ],
            "remark": "The output is a 2-element vector, which represents the probability of the input image belonging to each class"
        }
    },
    "config": {
        "url": "configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py"
    },
    "guidelines": "",
    "license": "MIT",
    "image": "https://files.seeedstudio.com/sscma/static/person_cls.png",
    "classes": [
        "Not a person",
        "Person"
    ],
    "benchmark": [
        {
            "backend": "PyTorch",
            "precision": "FLOAT32",
            "metrics": {
                "Top-1(%)": 88.37,
                "Flops(MB)": 76.5,
                "Params(M)": 2.71
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/classification/models/person/mobilenetv2_0.35rep_vww96_float32_sha1_0b47deccb4ffab4d8f970ea6379b838163e5bd8f.pth",
            "author": "Seeed Studio",
            "checksum": "md5:d29fae6afd2e9069d8df46df61e6b6fa"
        },
        {
            "backend": "ONNX",
            "precision": "FLOAT32",
            "metrics": {
                "Top-1(%)": 88.36,
                "Params(M)": 2.71
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/classification/models/person/mobilenetv2_0.35rep_vww96_float32_sha1_689cbad95dc725880861e72b5b9f7878f04ce17f.onnx",
            "author": "Seeed Studio",
            "checksum": "md5:11cab18ffe33314ac59e7c3dc0ba9280"
        },
        {
            "backend": "TFLite",
            "precision": "FLOAT32",
            "metrics": {
                "Top-1(%)": 88.36,
                "Params(M)": 2.71
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/classification/models/person/mobilenetv2_0.35rep_vww96_float32_sha1_a92eb1b9420f2947bfb65153e1def12097fdb977.tflite",
            "author": "Seeed Studio",
            "checksum": "md5:7ff86dbf4e69ecd035344da4abb1988d"
        },
        {
            "backend": "TFLite",
            "precision": "INT8",
            "device": [
                "xiao_esp32s3"
            ],
            "metrics": {
                "Top-1(%)": 88.27,
                "Params(M)": 2.71,
                "Inference(ms)": {
                    "xiao_esp32s3": 582
                }
            },
            "url": "https://files.seeedstudio.com/sscma/model_zoo/classification/models/person/mobilenetv2_0.35rep_vww96_int8_sha1_f1a66ce5a3f05bc1293920e5a95f547e27df6550.tflite",
            "author": "Seeed Studio",
            "checksum": "md5:beb714685e497664b90c98a5cfa66aba"
        }
    ]
}